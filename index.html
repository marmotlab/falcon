<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FALCON: Actively Decoupled Visuomotor Policies</title>
  <!-- Favicons -->
  <link rel="icon" href="assets/icon/falcon.png" sizes="32x32" type="image/png">
  <link rel="icon" href="assets/icon/falcon.png" sizes="16x16" type="image/png">
  <link rel="apple-touch-icon" href="assets/icon/falcon.png" sizes="180x180">
  <meta name="theme-color" content="#8C1515">
  <link rel="stylesheet" href="css/style.css">
  <script defer src="js/main.js"></script>
</head>
<body>


    <!-- Hero Section -->
    <header class="hero">
        <!-- Background video (muted, autoplay, loop). Placed before .container so it sits behind the content. -->
        <video class="hero-bg-video" autoplay muted loop playsinline preload="auto" aria-hidden="true">
          <source src="assets/icon/go2arm_video.mp4" type="video/mp4">
          <!-- fallback text intentionally empty -->
        </video>
        <div class="container">
      <h1>
        <span class="brand"><img src="assets/icon/falcon.png" alt="FALCON" class="title-icon">FALCON:</span>
        <span class="title-text"> <span class="highlight">Actively Decoupled Visuomotor Policies</span> for Loco-Manipulation with <span class="highlight">Foundation-Model-Based</span> Coordination</span>
      </h1>
            <!-- 新增作者列表 -->
            <div class="authors">
              <p>
                Chengyang He<sup>*</sup>,
                Sun Ge<sup>*</sup>,
                Yue Bai<sup></sup>,
                Junkai Lu<sup></sup>,
                Jiadong Zhao<sup></sup>,
                Guillaume Sartoretti<sup></sup>
              </p>
            </div>
            <div class="affiliations">
              <p><sup></sup>National University of Singapore</p>
              <!-- <p><sup>1</sup>Equal Contribution</p> -->
            </div>
        </div>
    </header>
    <!-- Navbar -->
    <nav class="navbar">
        <div class="container">
            <a class="logo" href="index.html">
                <img src="assets/logo.png" alt="Logo" />
            </a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="#abstract">Abstract</a></li>
                <li><a href="#framework">Framework</a></li>
                <li class="has-dropdown">
                  <a href="#result" aria-haspopup="true" aria-expanded="false">Result</a>
                  <ul class="dropdown" aria-label="Result submenu">
                    <li><a href="#result">Overview</a></li>
                    <li><a href="#task1">Task1</a></li>
                    <li><a href="#task2">Task2</a></li>
                  </ul>
                </li>
                <li><a href="#videos">Video</a></li>
                <!-- <li><a href="#publications">Paper</a></li> -->
                <li><a href="about.html">Team</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>


    <!-- Top Logos -->
    <div class="top-logos">
        <div class="container logo-row">
          <img src="assets/logos/marmot_logo.png" alt="marmot" class="logo1">
          <img src="assets/logos/nus_logo.png" alt="nus" class="logo2">
        </div>
    </div>

    <section id="abstract" class="section">
      <div class="container">
        <h2>Abstract</h2>
                <div class="hero-text-img">
              <p> <img src="assets/figure/banner.png" alt="Illustration" class="wrap-img">

                  We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision–language foundation model as the coordinator. 
                  Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. 
                  This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation.
                  Our key innovation lies in restoring coordination between these two independent policies through a vision–language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. 
                  On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels.
                  To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. 
                  We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. 
                  Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.</p>
      </div>
      </div>
    </section>
    <!-- Framework Section -->
    <section id="framework" class="section">
      <div class="container">
        <h2>Framework</h2>
        <p><img src="assets/figure/framework_straight.png" alt="Illustration" class="wrap-img">
          The blue and green regions denote the decoupled manipulator and quadruped diffusion policies, which act in their own observation and control spaces (wrist/body cameras and end-effector pose for the arm; head/body cameras, base velocity, and body height/pitch for the quadruped). 
          The yellow region shows the foundation model module, which aggregates global RGB observations and the language instruction into a shared latent, while capture task phase and progress simultaneously; this task-representative latent is then used to jointly condition both diffusion policies, providing semantic coordination between the two subsystems.
        </p>
      </div>
    </section>

    <section id="result" class="section">
      <div class="container">
        <h2>Result</h2>
        <p><img src="assets/figure/pic2.png" alt="Illustration" class="wrap-img">
          Overview of the manipulation tasks. 
          The task on the left shows the quadruped–manipulator system approaching the drawer, adjusting its base pose for optimal arm reachability, opening the drawer, and placing a toy inside. 
          The task on the right illustrates a complementary scenario in which the robot navigates to the drawer while holding a toy, places the toy into the already opened drawer, and then closes the drawer using pose-assisted whole-body manipulation. The top row shows synchronized egocentric camera observations for each stage, color-coded to match the corresponding robot pose, while the bottom row depicts the whole-body motions generated by the decoupled locomotion and manipulation policies.
        </p>
        <div class="Task1-results">
          <h3 id="task1">Task1 Results: </h3>
          <h4>Task1 – Result of FALCON (10× Speed)</h4>
          <div class="two-column-videos">
            <div class="left-big">
              <video autoplay loop muted playsinline>
                <source src="assets/Task1_results/rqt/Task1_rqt_10_1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="right-stack">
              <video autoplay loop muted playsinline>
                <source src="assets/Task1_results/rqt/Task1_rqt_10_C1.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline>
                <source src="assets/Task1_results/rqt/Task1_rqt_10_C2.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline>
                <source src="assets/Task1_results/rqt/Task1_rqt_10_C3.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <h4>Task1 – Human-in-the-Loop: Teleoperate Subsystem (10× Speed)</h4>
            <!-- 2x3 grid: 1 image + 5 videos (all same size). Hover to enlarge on pointer devices. -->
            <div class="grid-2x3">
              <div class="grid-item">
                <!-- placeholder image; replace with a Task1-specific thumbnail if available -->
                <img src="assets/figure/pic3.png" alt="Task1 thumbnail" />
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task1_results/human_teleoperation/Task1_human_teleoperation1.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task1_results/human_teleoperation/Task1_human_teleoperation2.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task1_results/human_teleoperation/Task1_human_teleoperation3.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task1_results/human_teleoperation/Task1_human_teleoperation4.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task1_results/human_teleoperation/Task1_human_teleoperation5.mp4" type="video/mp4">
                </video>
              </div>
            </div>

        <div class="Task2-results">
          <h3 id="task2">Task2 Results: </h3>
          <h4>Task2 – Result of FALCON (10× Speed)</h4>
          <div class="two-column-videos">
            <div class="left-big">
              <video autoplay loop muted playsinline>
                <source src="assets/Task2_results/rqt/Task2_rqt_10_1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="right-stack">
              <video autoplay loop muted playsinline>
                <source src="assets/Task2_results/rqt/Task2_rqt_10_C1.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline>
                <source src="assets/Task2_results/rqt/Task2_rqt_10_C2.mp4" type="video/mp4">
              </video>
              <video autoplay loop muted playsinline>
                <source src="assets/Task2_results/rqt/Task2_rqt_10_C3.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <h4>Task2 – Human-in-the-Loop: Teleoperate Subsystem (10× Speed)</h4>
            <!-- 2x3 grid: 1 image + 5 videos (all same size). Hover to enlarge on pointer devices. -->
            <div class="grid-2x3">
              <div class="grid-item">
                <!-- placeholder image; replace with a Task2-specific thumbnail if available -->
                <img src="assets/figure/pic3.png" alt="Task2 thumbnail" />
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task2_results/human_teleoperation/Task2_human_teleoperation1.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task2_results/human_teleoperation/Task2_human_teleoperation2.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task2_results/human_teleoperation/Task2_human_teleoperation3.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task2_results/human_teleoperation/Task2_human_teleoperation4.mp4" type="video/mp4">
                </video>
              </div>
              <div class="grid-item">
                <video autoplay loop muted playsinline>
                  <source src="assets/Task2_results/human_teleoperation/Task2_human_teleoperation5.mp4" type="video/mp4">
                </video>
              </div>
            </div>

          <h4>Task2 – Initial robot positions and example navigation trajectories (10× Speed)</h4>
          <p><img src="assets/Task2_results/Task2_9_position.png" alt="Illustration" class="wrap-img">
          Initial robot positions and example navigation trajectories for Task~2. 
          The robot begins from multiple starting locations across the workspace and navigates toward the opened drawer. 
          The color-coding indicates the three evaluation regions: green for the left area, orange for the center area, and blue for the right area. 
          Note that the training data are primarily collected from the center region, making the left and right regions predominantly out-of-distribution (OOD) during evaluation.  
          </p>
          <div class="s1-video-mid">
            <video autoplay loop muted playsinline>
              <source src="assets/Task2_results/Task2_9_position.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            </div>
        </div>
      </div>
    </section>

  <!-- Full Videos -->
  <section id="videos" class="section video-section">
    <div class="container">
      <h2>Introduction Video</h2>
      <div class="video-wrapper intro">
        <video class="intro-video" loop muted playsinline>
          <source src="assets/demo/demo.mp4" type="video/mp4">
          Your browser does not support HTML5 video.
        </video>
        <button class="video-overlay" aria-label="Play introduction video">
          <!-- Simple play icon (SVG) -->
          <svg viewBox="0 0 100 100" aria-hidden="true" focusable="false">
            <circle cx="50" cy="50" r="48" fill="rgba(0,0,0,0.35)" />
            <polygon points="40,30 70,50 40,70" fill="#fff" />
          </svg>
        </button>
      </div>
    </div>
  </section>

    <!-- Publications
    <section id="publications" class="section">
        <div class="container">
            <h2>Bibtex</h2>
            <pre class="bibtex"><code>@article{xxxx,
  title={FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination},
  author={He, Chengyang and Sun, Ge and Bai, Yue and Lu, Junkai and Zhao, Jiadong and Sartoretti, Guillaume},
  journal={arXiv preprint arXiv:XXXXX},
  year={2025}
}</code></pre>
        </div>
    </section> -->

    <!-- Contact -->
    <section id="contact" class="section">
        <div class="container">
            <h2>Contact</h2>
            <p>If you have any questions, feel free to contact <a href="mailto:chengyanghe@u.nus.edu">Chengyang He</a>
              , <a href="mailto:sunge@u.nus.edu">Ge Sun</a>
              , <a href="mailto:y_bai.07@u.nus.edu">Yue Bai</a>
              , <a href="mailto:junkai.lu@u.nus.edu">Junkai Lu</a>
               and <a href="mailto:zhaojiadong@u.nus.edu">Jiadong Zhao</a>.</p>
        </div>
    </section>


    <footer>
        <div class="container">
            <p>© 2025 FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</p>
        </div>
    </footer>
</body>
</html>

